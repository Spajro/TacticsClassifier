{
  "cells": [
    {
      "metadata": {
        "id": "9dfc98def8fb55f"
      },
      "cell_type": "markdown",
      "source": [
        "# LOADING DATASET"
      ],
      "id": "9dfc98def8fb55f"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install zstandard\n",
        "!pip install chess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N75JnRl7ei5w",
        "outputId": "a7192521-2646-4b7c-df8d-59bee09ca08b"
      },
      "id": "N75JnRl7ei5w",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zstandard\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zstandard\n",
            "Successfully installed zstandard-0.22.0\n",
            "Collecting chess\n",
            "  Downloading chess-1.10.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: chess\n",
            "Successfully installed chess-1.10.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "c4b51d4c10754771",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:46:11.177071Z",
          "start_time": "2024-06-13T00:46:11.174305Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import urllib\n",
        "import zstandard\n",
        "import chess\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import math\n",
        "import time"
      ],
      "id": "c4b51d4c10754771",
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "use_wandb = False"
      ],
      "metadata": {
        "id": "9nu8ljjL97Z0"
      },
      "execution_count": 41,
      "outputs": [],
      "id": "9nu8ljjL97Z0"
    },
    {
      "cell_type": "code",
      "source": [
        "if use_wandb:\n",
        "    !pip install wandb\n",
        "    import wandb\n",
        "    wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "Zr1MZ0PVPr3U",
        "outputId": "16736345-9a97-4817-f22c-c3ca11ae1f9d"
      },
      "id": "Zr1MZ0PVPr3U",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.17.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.5.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.5.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "c1af7d40bfdbe229",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:20.817121Z",
          "start_time": "2024-06-13T00:37:20.813298Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def __download(url: str, name: str) -> str:\n",
        "    path, _ = urllib.request.urlretrieve(url, name)\n",
        "    return path\n",
        "\n",
        "\n",
        "def __unpack(path: str, name: str):\n",
        "    input_file = pathlib.Path(path)\n",
        "    with open(input_file, 'rb') as compressed:\n",
        "        decomp = zstandard.ZstdDecompressor()\n",
        "        output_path = name\n",
        "        with open(output_path, 'wb') as destination:\n",
        "            decomp.copy_stream(compressed, destination)\n",
        "            destination.close()\n",
        "        compressed.close()\n",
        "\n",
        "\n",
        "def __remove(path: str):\n",
        "    pathlib.Path.unlink(pathlib.Path(path))"
      ],
      "id": "c1af7d40bfdbe229",
      "outputs": [],
      "execution_count": 5
    },
    {
      "metadata": {
        "id": "7b7f765e257cee1f",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:39.185545Z",
          "start_time": "2024-06-13T00:37:20.817654Z"
        }
      },
      "cell_type": "code",
      "source": [
        "path = __download(\"https://database.lichess.org/lichess_db_puzzle.csv.zst\", \"lichess_db_puzzle.csv.zst\")"
      ],
      "id": "7b7f765e257cee1f",
      "outputs": [],
      "execution_count": 6
    },
    {
      "metadata": {
        "id": "ca1de55ee484bb4e",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.138174Z",
          "start_time": "2024-06-13T00:37:39.186549Z"
        }
      },
      "cell_type": "code",
      "source": [
        "__unpack(path, \"lichess_db_puzzle.csv\")"
      ],
      "id": "ca1de55ee484bb4e",
      "outputs": [],
      "execution_count": 7
    },
    {
      "metadata": {
        "id": "876c56ec9a7ac80d",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.152895Z",
          "start_time": "2024-06-13T00:37:40.138174Z"
        }
      },
      "cell_type": "code",
      "source": [
        "__remove(\"lichess_db_puzzle.csv.zst\")"
      ],
      "id": "876c56ec9a7ac80d",
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.156833Z",
          "start_time": "2024-06-13T00:37:40.153899Z"
        }
      },
      "source": [
        "class Puzzle:\n",
        "    def __init__(self, row: str):\n",
        "        fields = row.split(',')\n",
        "        self.fen = fields[1]\n",
        "        self.moves = fields[2].split(\" \")\n",
        "        self.tags = fields[7].split(\" \")\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"{fen: \" + self.fen + \" ,tags: [\" + \", \".join(self.tags) + \"],moves: [\" + \",\".join(self.moves) + \"]}\""
      ],
      "outputs": [],
      "execution_count": 9
    },
    {
      "metadata": {
        "id": "d76ee6cf90617af0",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.162536Z",
          "start_time": "2024-06-13T00:37:40.157383Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def load(k: int) -> [Puzzle]:\n",
        "    f = open(\"lichess_db_puzzle.csv\")\n",
        "    f.readline()\n",
        "    result = []\n",
        "    for i in range(k):\n",
        "        result.append(Puzzle(f.readline()))\n",
        "    f.close()\n",
        "    return result"
      ],
      "id": "d76ee6cf90617af0",
      "outputs": [],
      "execution_count": 10
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "57feb45f444a7d0a",
        "outputId": "013e3bd7-b5cc-4680-8ef2-54bfb354c4ee",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.169216Z",
          "start_time": "2024-06-13T00:37:40.162536Z"
        }
      },
      "cell_type": "code",
      "source": [
        "load(10)[0].__str__()"
      ],
      "id": "57feb45f444a7d0a",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{fen: r6k/pp2r2p/4Rp1Q/3p4/8/1N1P2R1/PqP2bPP/7K b - - 0 24 ,tags: [crushing, hangingPiece, long, middlegame],moves: [f2g3,e6e7,b2b1,b3c1,b1c1,h6c1]}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "execution_count": 11
    },
    {
      "metadata": {
        "id": "f362b99117932533"
      },
      "cell_type": "markdown",
      "source": [
        "# FILTER DATASET"
      ],
      "id": "f362b99117932533"
    },
    {
      "metadata": {
        "id": "54b9c024e9edbc45",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.173130Z",
          "start_time": "2024-06-13T00:37:40.169308Z"
        }
      },
      "cell_type": "code",
      "source": [
        "expected_tags = {\n",
        "    'attraction',\n",
        "    'discoveredAttack',\n",
        "    'doubleCheck',\n",
        "    'fork',\n",
        "    'pin',\n",
        "    'sacrifice',\n",
        "    'skewer',\n",
        "    'xRayAttack',\n",
        "    'zugzwang',\n",
        "    'deflection',\n",
        "    'clearance'\n",
        "}"
      ],
      "id": "54b9c024e9edbc45",
      "outputs": [],
      "execution_count": 12
    },
    {
      "metadata": {
        "id": "b4c7b42dafb2af34",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.178410Z",
          "start_time": "2024-06-13T00:37:40.173637Z"
        }
      },
      "cell_type": "code",
      "source": [
        "expected_tags_list = list(expected_tags)"
      ],
      "id": "b4c7b42dafb2af34",
      "outputs": [],
      "execution_count": 13
    },
    {
      "metadata": {
        "id": "68a75e47bbf20450",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.183229Z",
          "start_time": "2024-06-13T00:37:40.178410Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def filter_data(data: [Puzzle]) -> [Puzzle]:\n",
        "    return list(filter(lambda p: len(set(p.tags) & expected_tags) == 1, data))"
      ],
      "id": "68a75e47bbf20450",
      "outputs": [],
      "execution_count": 14
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed1341d0f35d0c64",
        "outputId": "ed323038-49e1-4670-f0be-3271655b830d",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.189325Z",
          "start_time": "2024-06-13T00:37:40.183229Z"
        }
      },
      "cell_type": "code",
      "source": [
        "len(filter_data(load(100)))"
      ],
      "id": "ed1341d0f35d0c64",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "execution_count": 15
    },
    {
      "metadata": {
        "id": "a5c92e35f0ad916d"
      },
      "cell_type": "markdown",
      "source": [
        "# CONVERSION TO TENSOR"
      ],
      "id": "a5c92e35f0ad916d"
    },
    {
      "metadata": {
        "id": "10c35e85f53b2f3c",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.194334Z",
          "start_time": "2024-06-13T00:37:40.189325Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def bitboard_to_tensor(bitboard: int) -> torch.Tensor:\n",
        "    li = [1 if digit == '1' else 0 for digit in bin(bitboard)[2:]]\n",
        "    li = [0 for _ in range(64 - len(li))] + li\n",
        "    return torch.tensor(li).reshape((8, 8))"
      ],
      "id": "10c35e85f53b2f3c",
      "outputs": [],
      "execution_count": 16
    },
    {
      "metadata": {
        "id": "ac21f78c3f6922b4",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.199814Z",
          "start_time": "2024-06-13T00:37:40.194334Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def fen_to_tensors_list(fen: str) -> [torch.Tensor]:\n",
        "    board = chess.Board(fen)\n",
        "    return [\n",
        "        bitboard_to_tensor(board.occupied_co[chess.WHITE]),\n",
        "        bitboard_to_tensor(board.occupied_co[chess.BLACK]),\n",
        "        bitboard_to_tensor(board.pawns),\n",
        "        bitboard_to_tensor(board.kings),\n",
        "        bitboard_to_tensor(board.queens),\n",
        "        bitboard_to_tensor(board.knights),\n",
        "        bitboard_to_tensor(board.bishops),\n",
        "        bitboard_to_tensor(board.rooks)\n",
        "    ]"
      ],
      "id": "ac21f78c3f6922b4",
      "outputs": [],
      "execution_count": 17
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2af6bc1bbdd66c04",
        "outputId": "cccc6312-5a7b-4754-8b8c-841831f7f87b",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.224544Z",
          "start_time": "2024-06-13T00:37:40.199814Z"
        }
      },
      "cell_type": "code",
      "source": [
        "fen_to_tensors_list(load(1)[0].fen)"
      ],
      "id": "2af6bc1bbdd66c04",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 0, 0, 1, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 1, 0, 0, 1, 0, 1, 0],\n",
              "         [1, 1, 0, 0, 0, 1, 0, 1],\n",
              "         [1, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " tensor([[1, 0, 0, 0, 0, 0, 0, 1],\n",
              "         [1, 0, 0, 1, 0, 0, 1, 1],\n",
              "         [0, 0, 1, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 1, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 1, 0, 0, 0, 1, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 0, 0, 0, 0, 0, 1, 1],\n",
              "         [0, 0, 1, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 1, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 1, 0, 0, 0],\n",
              "         [1, 1, 0, 0, 0, 1, 0, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " tensor([[1, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 1, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 1, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 1, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " tensor([[0, 0, 0, 0, 0, 0, 0, 1],\n",
              "         [0, 0, 0, 1, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 1, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 1, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0]])]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "execution_count": 18
    },
    {
      "metadata": {
        "id": "17c3f21abe4260e5",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.227546Z",
          "start_time": "2024-06-13T00:37:40.224544Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def move_to_tensor(move: str) -> torch.Tensor:\n",
        "    x1 = 7 - ord(move[0]) + ord('a')\n",
        "    y1 = 8 - int(move[1])\n",
        "    x2 = 7 - ord(move[2]) + ord('a')\n",
        "    y2 = 8 - int(move[3])\n",
        "    tensor = torch.zeros(8, 8)\n",
        "    tensor[y1][x1] = 1\n",
        "    tensor[y2][x2] = 1\n",
        "    return tensor"
      ],
      "id": "17c3f21abe4260e5",
      "outputs": [],
      "execution_count": 19
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "104d99da6a271a6a",
        "outputId": "befc5adc-0f81-40db-e6be-f06752456c63",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.255153Z",
          "start_time": "2024-06-13T00:37:40.251971Z"
        }
      },
      "cell_type": "code",
      "source": [
        "print(move_to_tensor('e2e4'))"
      ],
      "id": "104d99da6a271a6a",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ],
      "execution_count": 20
    },
    {
      "metadata": {
        "id": "7d58e2f64a04bec6",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.260584Z",
          "start_time": "2024-06-13T00:37:40.255153Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def puzzle_to_tensor(puzzle: Puzzle) -> torch.Tensor:\n",
        "    fen_tensors = fen_to_tensors_list(puzzle.fen)\n",
        "    move_tensors = [move_to_tensor(puzzle.moves[0]), move_to_tensor(puzzle.moves[1])]  # FIRST TWO MOVES\n",
        "    return torch.stack(fen_tensors + move_tensors)"
      ],
      "id": "7d58e2f64a04bec6",
      "outputs": [],
      "execution_count": 21
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f086ac45785396dd",
        "outputId": "3a271cb0-a5d8-49ea-e55a-08abcd9595b7",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:40.269419Z",
          "start_time": "2024-06-13T00:37:40.260584Z"
        }
      },
      "cell_type": "code",
      "source": [
        "puzzle_to_tensor(load(1)[0])"
      ],
      "id": "f086ac45785396dd",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 1., 0., 1., 0.],\n",
              "         [1., 1., 0., 0., 0., 1., 0., 1.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [1., 0., 0., 1., 0., 0., 1., 1.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 1., 1.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [1., 1., 0., 0., 0., 1., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "execution_count": 22
    },
    {
      "metadata": {
        "id": "577ba77d6cc0369a"
      },
      "cell_type": "markdown",
      "source": [
        "# CONVERT AND BATCH DATASET"
      ],
      "id": "577ba77d6cc0369a"
    },
    {
      "metadata": {
        "id": "f69689ed3c928f55",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:54.037937Z",
          "start_time": "2024-06-13T00:37:54.034936Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def puzzle_to_truth(puzzle: Puzzle) -> torch.Tensor:\n",
        "    tensor = torch.zeros(len(expected_tags_list))\n",
        "    [tag] = set(puzzle.tags) & expected_tags\n",
        "    index = expected_tags_list.index(tag)\n",
        "    tensor[index] = 1\n",
        "    return torch.zeros(1) + index"
      ],
      "id": "f69689ed3c928f55",
      "outputs": [],
      "execution_count": 23
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abd55187edfe5df",
        "outputId": "4f551bab-0548-4e8c-d135-d749ad03bf9c",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:54.564564Z",
          "start_time": "2024-06-13T00:37:54.559906Z"
        }
      },
      "cell_type": "code",
      "source": [
        "puzzle_to_truth(filter_data(load(100))[0])"
      ],
      "id": "abd55187edfe5df",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "execution_count": 24
    },
    {
      "metadata": {
        "id": "bf6296834a2068eb",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:55.097646Z",
          "start_time": "2024-06-13T00:37:55.094647Z"
        }
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64"
      ],
      "id": "bf6296834a2068eb",
      "outputs": [],
      "execution_count": 25
    },
    {
      "metadata": {
        "id": "2a98f0f8bbd52026",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:55.445902Z",
          "start_time": "2024-06-13T00:37:55.443465Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def convert_dataset(puzzles: [Puzzle]) -> list[tuple[torch.Tensor, torch.Tensor]]:\n",
        "    return [(puzzle_to_tensor(puzzle), puzzle_to_truth(puzzle)) for puzzle in puzzles]"
      ],
      "id": "2a98f0f8bbd52026",
      "outputs": [],
      "execution_count": 26
    },
    {
      "metadata": {
        "id": "37b1f86d84eb8476",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:55.796130Z",
          "start_time": "2024-06-13T00:37:55.793450Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def dataset_to_batches(dataset: list[tuple[torch.Tensor, torch.Tensor]]) -> list[tuple[torch.Tensor, torch.Tensor]]:\n",
        "    batches = []\n",
        "    index = 0\n",
        "    while index + BATCH_SIZE <= len(dataset):\n",
        "        batch = []\n",
        "        truth = []\n",
        "        max_index = index + BATCH_SIZE\n",
        "        while index < max_index:\n",
        "            batch.append(dataset[index][0])\n",
        "            truth.append(dataset[index][1])\n",
        "            index += 1\n",
        "        batches.append((torch.stack(batch).cuda(), torch.tensor(truth).cuda().type(torch.long)))\n",
        "\n",
        "    return batches"
      ],
      "id": "37b1f86d84eb8476",
      "outputs": [],
      "execution_count": 27
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c6ecc1932649601",
        "outputId": "8933c3d4-4361-4807-f55a-27ce7c400465",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:57.496271Z",
          "start_time": "2024-06-13T00:37:56.701133Z"
        }
      },
      "cell_type": "code",
      "source": [
        "batched_dataset=dataset_to_batches(convert_dataset(filter_data(load(10000))))\n",
        "print(len(batched_dataset))\n",
        "print(batched_dataset[0][0].shape,batched_dataset[0][1].shape)"
      ],
      "id": "2c6ecc1932649601",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47\n",
            "torch.Size([64, 10, 8, 8]) torch.Size([64])\n"
          ]
        }
      ],
      "execution_count": 28
    },
    {
      "metadata": {
        "id": "dd2e455b1a377348"
      },
      "cell_type": "markdown",
      "source": [
        "# TRAIN"
      ],
      "id": "dd2e455b1a377348"
    },
    {
      "metadata": {
        "id": "ab02ddd180fcdd69",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:37:58.852313Z",
          "start_time": "2024-06-13T00:37:58.849810Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def accuracy(out,truth):\n",
        "    return torch.argmax(out,dim=1) == truth"
      ],
      "id": "ab02ddd180fcdd69",
      "outputs": [],
      "execution_count": 29
    },
    {
      "metadata": {
        "id": "27c76f74edc787d2",
        "ExecuteTime": {
          "end_time": "2024-06-13T02:21:04.311882Z",
          "start_time": "2024-06-13T02:21:04.307678Z"
        }
      },
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(Model, self).__init__()\n",
        "        self.classifier = nn.Sequential(*args, **kwargs)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.classifier.forward(X)\n",
        "\n",
        "\n",
        "model = Model(nn.Conv2d(10, 8 * 8, kernel_size=4, padding=4),\n",
        "              nn.ReLU(),\n",
        "              nn.Conv2d(8 * 8, 4 * 4, kernel_size=2, padding=4),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(kernel_size=4, stride=1),\n",
        "              nn.Conv2d(4*4, 8 * 8, kernel_size=2, padding=4),\n",
        "              nn.ReLU(),\n",
        "              nn.Conv2d(8 * 8, 1, kernel_size=4, padding=4),\n",
        "              nn.ReLU(),\n",
        "              nn.Flatten(),\n",
        "              nn.Linear(841, 256),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(256, 64),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(64, 11),\n",
        "              nn.LogSoftmax(),\n",
        "              )\n",
        "criterion = (\n",
        "    nn.NLLLoss()\n",
        ")\n"
      ],
      "id": "27c76f74edc787d2",
      "outputs": [],
      "execution_count": 30
    },
    {
      "metadata": {
        "id": "230d17a6081a7ffc",
        "ExecuteTime": {
          "end_time": "2024-06-13T02:01:54.301737Z",
          "start_time": "2024-06-13T02:01:54.299361Z"
        }
      },
      "cell_type": "code",
      "source": [
        "size_to_load=3000000\n",
        "test_batches_count=500"
      ],
      "id": "230d17a6081a7ffc",
      "outputs": [],
      "execution_count": 31
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1a9a9709411156f",
        "outputId": "661893fb-3a71-4e00-9a30-8ada81150da8",
        "ExecuteTime": {
          "end_time": "2024-06-13T01:18:14.211422Z",
          "start_time": "2024-06-13T01:13:08.204663Z"
        }
      },
      "cell_type": "code",
      "source": [
        "all_batches=dataset_to_batches(convert_dataset(filter_data(load(size_to_load))))\n",
        "train_batches=all_batches[test_batches_count:]\n",
        "test_batches=all_batches[:test_batches_count]\n",
        "print(len(all_batches),len(train_batches),len(test_batches))"
      ],
      "id": "d1a9a9709411156f",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14131 13631 500\n"
          ]
        }
      ],
      "execution_count": 32
    },
    {
      "metadata": {
        "id": "52588422f107c263",
        "ExecuteTime": {
          "end_time": "2024-06-13T01:18:14.215912Z",
          "start_time": "2024-06-13T01:18:14.212426Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, epoch):\n",
        "    model.cuda()\n",
        "    criterion.cuda()\n",
        "    batches = train_batches\n",
        "    size=len(batches)\n",
        "    print(\"Dataset size:\", len(batches))\n",
        "    for i in range(epoch):\n",
        "        time_started = time.time() * 1000\n",
        "        loss_sum=0.0\n",
        "        accuracy_sum=0.0\n",
        "        for batch, truth in batches:\n",
        "            optimizer.zero_grad()\n",
        "            out = model.forward(batch)\n",
        "            loss = criterion(out, truth)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            accuracy_value = accuracy(out,truth).sum()/BATCH_SIZE\n",
        "\n",
        "            loss_sum+=loss.item()\n",
        "            accuracy_sum+=accuracy_value.item()\n",
        "\n",
        "        passed_time = math.ceil(time.time() * 1000 - time_started)\n",
        "        loss_average = loss_sum/size\n",
        "        accuracy_average = accuracy_sum/size\n",
        "        print(f\"Epoch [{i+1}/{epoch}], train_loss: {loss_average}, train_accuracy: {accuracy_average}, time: {passed_time/1000}s\")\n",
        "        if use_wandb:\n",
        "            wandb.log({\"epoch\": i + 1, \"train_loss\": loss_average, \"train_accuracy\" : accuracy_average})"
      ],
      "id": "52588422f107c263",
      "outputs": [],
      "execution_count": 49
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b500d4f989b86b92",
        "outputId": "0514fddb-5bb6-4c0a-965e-536d31d29e5f",
        "ExecuteTime": {
          "end_time": "2024-06-13T02:38:25.750332Z",
          "start_time": "2024-06-13T02:21:06.329349Z"
        }
      },
      "cell_type": "code",
      "source": [
        "train(model,\n",
        "      criterion,\n",
        "      torch.optim.SGD(model.classifier.parameters(), lr=0.01),\n",
        "      1)"
      ],
      "id": "b500d4f989b86b92",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 13631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], train_loss: 1.7287859148573748, train_accuracy: 0.4058327525493361, time: 62.301s\n"
          ]
        }
      ],
      "execution_count": 34
    },
    {
      "metadata": {
        "id": "1f69aaab85e1966a",
        "ExecuteTime": {
          "end_time": "2024-06-13T00:45:32.211009Z",
          "start_time": "2024-06-13T00:45:32.211009Z"
        }
      },
      "cell_type": "code",
      "source": [
        "torch.save(model,'model.pt')"
      ],
      "id": "1f69aaab85e1966a",
      "outputs": [],
      "execution_count": 35
    },
    {
      "metadata": {
        "id": "c8251ffcc9b16e94",
        "ExecuteTime": {
          "end_time": "2024-06-13T02:38:36.224125Z",
          "start_time": "2024-06-13T02:38:36.221341Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def test(model, criterion):\n",
        "    model.cuda()\n",
        "    criterion.cuda()\n",
        "    batches = test_batches\n",
        "    print(\"Dataset size:\", len(batches))\n",
        "    batch_index = 0\n",
        "\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    for i in range(len(batches)):\n",
        "\n",
        "        batch = batches[i][0]\n",
        "        truth = batches[i][1]\n",
        "\n",
        "        if batch_index == len(batches):\n",
        "            batch_index = 0\n",
        "\n",
        "        out = model.forward(batch)\n",
        "        loss = criterion(out, truth)\n",
        "        print(f\"Batch [{i+1}/{len(batches)}], test_loss: {loss.item()}, test_accuracy: {(accuracy(out,truth).sum()/BATCH_SIZE).item()}\")\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_accuracy+=(accuracy(out,truth).sum()/BATCH_SIZE).item()\n",
        "\n",
        "    return (total_loss / len(batches)),total_accuracy / len(batches)"
      ],
      "id": "c8251ffcc9b16e94",
      "outputs": [],
      "execution_count": 36
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac9a5368131bcb1d",
        "outputId": "ae1a0efc-5fc0-4478-d9fa-cc052d618f2b",
        "ExecuteTime": {
          "end_time": "2024-06-13T02:38:43.059095Z",
          "start_time": "2024-06-13T02:38:42.517795Z"
        }
      },
      "cell_type": "code",
      "source": [
        "test(model, criterion)"
      ],
      "id": "ac9a5368131bcb1d",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 500\n",
            "Batch [1/500], test_loss: 1.4913530349731445, test_accuracy: 0.46875\n",
            "Batch [2/500], test_loss: 1.5333746671676636, test_accuracy: 0.4375\n",
            "Batch [3/500], test_loss: 1.5793960094451904, test_accuracy: 0.46875\n",
            "Batch [4/500], test_loss: 1.4574456214904785, test_accuracy: 0.515625\n",
            "Batch [5/500], test_loss: 1.5792930126190186, test_accuracy: 0.4375\n",
            "Batch [6/500], test_loss: 1.6646337509155273, test_accuracy: 0.46875\n",
            "Batch [7/500], test_loss: 1.4459553956985474, test_accuracy: 0.421875\n",
            "Batch [8/500], test_loss: 1.4522058963775635, test_accuracy: 0.515625\n",
            "Batch [9/500], test_loss: 1.64620041847229, test_accuracy: 0.4375\n",
            "Batch [10/500], test_loss: 1.4456701278686523, test_accuracy: 0.5625\n",
            "Batch [11/500], test_loss: 1.8471453189849854, test_accuracy: 0.40625\n",
            "Batch [12/500], test_loss: 1.373580813407898, test_accuracy: 0.46875\n",
            "Batch [13/500], test_loss: 1.812636375427246, test_accuracy: 0.359375\n",
            "Batch [14/500], test_loss: 1.3551278114318848, test_accuracy: 0.46875\n",
            "Batch [15/500], test_loss: 1.639514446258545, test_accuracy: 0.390625\n",
            "Batch [16/500], test_loss: 1.5799754858016968, test_accuracy: 0.4375\n",
            "Batch [17/500], test_loss: 1.5839192867279053, test_accuracy: 0.4375\n",
            "Batch [18/500], test_loss: 1.5986156463623047, test_accuracy: 0.4375\n",
            "Batch [19/500], test_loss: 1.4903223514556885, test_accuracy: 0.546875\n",
            "Batch [20/500], test_loss: 1.479810357093811, test_accuracy: 0.5625\n",
            "Batch [21/500], test_loss: 1.6321336030960083, test_accuracy: 0.359375\n",
            "Batch [22/500], test_loss: 1.7223443984985352, test_accuracy: 0.359375\n",
            "Batch [23/500], test_loss: 1.6232045888900757, test_accuracy: 0.359375\n",
            "Batch [24/500], test_loss: 1.452455997467041, test_accuracy: 0.5\n",
            "Batch [25/500], test_loss: 1.5545315742492676, test_accuracy: 0.390625\n",
            "Batch [26/500], test_loss: 1.5703680515289307, test_accuracy: 0.546875\n",
            "Batch [27/500], test_loss: 1.6440905332565308, test_accuracy: 0.453125\n",
            "Batch [28/500], test_loss: 1.5899544954299927, test_accuracy: 0.4375\n",
            "Batch [29/500], test_loss: 1.4081814289093018, test_accuracy: 0.5\n",
            "Batch [30/500], test_loss: 1.5146280527114868, test_accuracy: 0.453125\n",
            "Batch [31/500], test_loss: 1.7803175449371338, test_accuracy: 0.390625\n",
            "Batch [32/500], test_loss: 1.6056041717529297, test_accuracy: 0.359375\n",
            "Batch [33/500], test_loss: 1.7726855278015137, test_accuracy: 0.4375\n",
            "Batch [34/500], test_loss: 1.3987659215927124, test_accuracy: 0.578125\n",
            "Batch [35/500], test_loss: 1.5632004737854004, test_accuracy: 0.421875\n",
            "Batch [36/500], test_loss: 1.5389468669891357, test_accuracy: 0.453125\n",
            "Batch [37/500], test_loss: 1.5528608560562134, test_accuracy: 0.40625\n",
            "Batch [38/500], test_loss: 1.4206517934799194, test_accuracy: 0.46875\n",
            "Batch [39/500], test_loss: 1.5047775506973267, test_accuracy: 0.375\n",
            "Batch [40/500], test_loss: 1.5440679788589478, test_accuracy: 0.5\n",
            "Batch [41/500], test_loss: 1.5133099555969238, test_accuracy: 0.515625\n",
            "Batch [42/500], test_loss: 1.6493231058120728, test_accuracy: 0.375\n",
            "Batch [43/500], test_loss: 1.4271750450134277, test_accuracy: 0.484375\n",
            "Batch [44/500], test_loss: 1.4380583763122559, test_accuracy: 0.484375\n",
            "Batch [45/500], test_loss: 1.7352101802825928, test_accuracy: 0.328125\n",
            "Batch [46/500], test_loss: 1.6854207515716553, test_accuracy: 0.296875\n",
            "Batch [47/500], test_loss: 1.654382586479187, test_accuracy: 0.453125\n",
            "Batch [48/500], test_loss: 1.600867509841919, test_accuracy: 0.40625\n",
            "Batch [49/500], test_loss: 1.4459071159362793, test_accuracy: 0.46875\n",
            "Batch [50/500], test_loss: 1.5690436363220215, test_accuracy: 0.421875\n",
            "Batch [51/500], test_loss: 1.55401611328125, test_accuracy: 0.453125\n",
            "Batch [52/500], test_loss: 1.6851179599761963, test_accuracy: 0.375\n",
            "Batch [53/500], test_loss: 1.5508466958999634, test_accuracy: 0.421875\n",
            "Batch [54/500], test_loss: 1.7157527208328247, test_accuracy: 0.4375\n",
            "Batch [55/500], test_loss: 1.6601544618606567, test_accuracy: 0.421875\n",
            "Batch [56/500], test_loss: 1.692883849143982, test_accuracy: 0.375\n",
            "Batch [57/500], test_loss: 1.6348241567611694, test_accuracy: 0.46875\n",
            "Batch [58/500], test_loss: 1.6523213386535645, test_accuracy: 0.484375\n",
            "Batch [59/500], test_loss: 1.4445172548294067, test_accuracy: 0.421875\n",
            "Batch [60/500], test_loss: 1.6420835256576538, test_accuracy: 0.46875\n",
            "Batch [61/500], test_loss: 1.6209758520126343, test_accuracy: 0.4375\n",
            "Batch [62/500], test_loss: 1.6375421285629272, test_accuracy: 0.4375\n",
            "Batch [63/500], test_loss: 1.7075998783111572, test_accuracy: 0.40625\n",
            "Batch [64/500], test_loss: 1.4601690769195557, test_accuracy: 0.46875\n",
            "Batch [65/500], test_loss: 1.555076003074646, test_accuracy: 0.46875\n",
            "Batch [66/500], test_loss: 1.664072871208191, test_accuracy: 0.46875\n",
            "Batch [67/500], test_loss: 1.519336462020874, test_accuracy: 0.5\n",
            "Batch [68/500], test_loss: 1.588196039199829, test_accuracy: 0.453125\n",
            "Batch [69/500], test_loss: 1.5393790006637573, test_accuracy: 0.40625\n",
            "Batch [70/500], test_loss: 1.4833941459655762, test_accuracy: 0.46875\n",
            "Batch [71/500], test_loss: 1.5113548040390015, test_accuracy: 0.421875\n",
            "Batch [72/500], test_loss: 1.7553918361663818, test_accuracy: 0.34375\n",
            "Batch [73/500], test_loss: 1.5133250951766968, test_accuracy: 0.46875\n",
            "Batch [74/500], test_loss: 1.4072661399841309, test_accuracy: 0.453125\n",
            "Batch [75/500], test_loss: 1.6932852268218994, test_accuracy: 0.359375\n",
            "Batch [76/500], test_loss: 1.4539318084716797, test_accuracy: 0.546875\n",
            "Batch [77/500], test_loss: 1.8255388736724854, test_accuracy: 0.3125\n",
            "Batch [78/500], test_loss: 1.5645942687988281, test_accuracy: 0.453125\n",
            "Batch [79/500], test_loss: 1.418883204460144, test_accuracy: 0.5\n",
            "Batch [80/500], test_loss: 1.6632367372512817, test_accuracy: 0.40625\n",
            "Batch [81/500], test_loss: 1.4144532680511475, test_accuracy: 0.578125\n",
            "Batch [82/500], test_loss: 1.8096394538879395, test_accuracy: 0.40625\n",
            "Batch [83/500], test_loss: 1.3863288164138794, test_accuracy: 0.515625\n",
            "Batch [84/500], test_loss: 1.601150393486023, test_accuracy: 0.4375\n",
            "Batch [85/500], test_loss: 1.46783447265625, test_accuracy: 0.53125\n",
            "Batch [86/500], test_loss: 1.3992644548416138, test_accuracy: 0.5\n",
            "Batch [87/500], test_loss: 1.5873507261276245, test_accuracy: 0.546875\n",
            "Batch [88/500], test_loss: 1.492846965789795, test_accuracy: 0.46875\n",
            "Batch [89/500], test_loss: 1.643738865852356, test_accuracy: 0.421875\n",
            "Batch [90/500], test_loss: 1.6070221662521362, test_accuracy: 0.40625\n",
            "Batch [91/500], test_loss: 1.3999255895614624, test_accuracy: 0.53125\n",
            "Batch [92/500], test_loss: 1.6383551359176636, test_accuracy: 0.359375\n",
            "Batch [93/500], test_loss: 1.5685944557189941, test_accuracy: 0.40625\n",
            "Batch [94/500], test_loss: 1.6711057424545288, test_accuracy: 0.34375\n",
            "Batch [95/500], test_loss: 1.5957797765731812, test_accuracy: 0.390625\n",
            "Batch [96/500], test_loss: 1.4520906209945679, test_accuracy: 0.515625\n",
            "Batch [97/500], test_loss: 1.3735198974609375, test_accuracy: 0.578125\n",
            "Batch [98/500], test_loss: 1.4274336099624634, test_accuracy: 0.546875\n",
            "Batch [99/500], test_loss: 1.7595267295837402, test_accuracy: 0.34375\n",
            "Batch [100/500], test_loss: 1.7116246223449707, test_accuracy: 0.375\n",
            "Batch [101/500], test_loss: 1.656863808631897, test_accuracy: 0.3125\n",
            "Batch [102/500], test_loss: 1.5796993970870972, test_accuracy: 0.34375\n",
            "Batch [103/500], test_loss: 1.4200061559677124, test_accuracy: 0.453125\n",
            "Batch [104/500], test_loss: 1.444385290145874, test_accuracy: 0.5\n",
            "Batch [105/500], test_loss: 1.4655342102050781, test_accuracy: 0.390625\n",
            "Batch [106/500], test_loss: 1.4625189304351807, test_accuracy: 0.484375\n",
            "Batch [107/500], test_loss: 1.331503987312317, test_accuracy: 0.546875\n",
            "Batch [108/500], test_loss: 1.6001436710357666, test_accuracy: 0.359375\n",
            "Batch [109/500], test_loss: 1.3478754758834839, test_accuracy: 0.546875\n",
            "Batch [110/500], test_loss: 1.6553279161453247, test_accuracy: 0.328125\n",
            "Batch [111/500], test_loss: 1.519453763961792, test_accuracy: 0.421875\n",
            "Batch [112/500], test_loss: 1.635846734046936, test_accuracy: 0.484375\n",
            "Batch [113/500], test_loss: 1.6932334899902344, test_accuracy: 0.359375\n",
            "Batch [114/500], test_loss: 1.5559303760528564, test_accuracy: 0.453125\n",
            "Batch [115/500], test_loss: 1.5650107860565186, test_accuracy: 0.46875\n",
            "Batch [116/500], test_loss: 1.585242509841919, test_accuracy: 0.4375\n",
            "Batch [117/500], test_loss: 1.6617627143859863, test_accuracy: 0.390625\n",
            "Batch [118/500], test_loss: 1.523207187652588, test_accuracy: 0.46875\n",
            "Batch [119/500], test_loss: 1.5978975296020508, test_accuracy: 0.375\n",
            "Batch [120/500], test_loss: 1.4931163787841797, test_accuracy: 0.4375\n",
            "Batch [121/500], test_loss: 1.636877179145813, test_accuracy: 0.375\n",
            "Batch [122/500], test_loss: 1.8996778726577759, test_accuracy: 0.3125\n",
            "Batch [123/500], test_loss: 1.6059863567352295, test_accuracy: 0.453125\n",
            "Batch [124/500], test_loss: 1.5437160730361938, test_accuracy: 0.4375\n",
            "Batch [125/500], test_loss: 1.4848073720932007, test_accuracy: 0.453125\n",
            "Batch [126/500], test_loss: 1.442855715751648, test_accuracy: 0.53125\n",
            "Batch [127/500], test_loss: 1.4930952787399292, test_accuracy: 0.53125\n",
            "Batch [128/500], test_loss: 1.7648074626922607, test_accuracy: 0.40625\n",
            "Batch [129/500], test_loss: 1.712325096130371, test_accuracy: 0.390625\n",
            "Batch [130/500], test_loss: 1.8250248432159424, test_accuracy: 0.34375\n",
            "Batch [131/500], test_loss: 1.7811930179595947, test_accuracy: 0.375\n",
            "Batch [132/500], test_loss: 1.5296220779418945, test_accuracy: 0.46875\n",
            "Batch [133/500], test_loss: 1.5596550703048706, test_accuracy: 0.421875\n",
            "Batch [134/500], test_loss: 1.5127406120300293, test_accuracy: 0.453125\n",
            "Batch [135/500], test_loss: 1.5637714862823486, test_accuracy: 0.453125\n",
            "Batch [136/500], test_loss: 1.6496288776397705, test_accuracy: 0.453125\n",
            "Batch [137/500], test_loss: 1.5820136070251465, test_accuracy: 0.453125\n",
            "Batch [138/500], test_loss: 1.3454455137252808, test_accuracy: 0.59375\n",
            "Batch [139/500], test_loss: 1.5632593631744385, test_accuracy: 0.4375\n",
            "Batch [140/500], test_loss: 1.3720215559005737, test_accuracy: 0.484375\n",
            "Batch [141/500], test_loss: 1.3873395919799805, test_accuracy: 0.46875\n",
            "Batch [142/500], test_loss: 1.5787461996078491, test_accuracy: 0.40625\n",
            "Batch [143/500], test_loss: 1.5533157587051392, test_accuracy: 0.40625\n",
            "Batch [144/500], test_loss: 1.536047101020813, test_accuracy: 0.515625\n",
            "Batch [145/500], test_loss: 1.5181102752685547, test_accuracy: 0.4375\n",
            "Batch [146/500], test_loss: 1.5065339803695679, test_accuracy: 0.53125\n",
            "Batch [147/500], test_loss: 1.4191728830337524, test_accuracy: 0.53125\n",
            "Batch [148/500], test_loss: 1.3870892524719238, test_accuracy: 0.5\n",
            "Batch [149/500], test_loss: 1.487757682800293, test_accuracy: 0.484375\n",
            "Batch [150/500], test_loss: 1.6589717864990234, test_accuracy: 0.453125\n",
            "Batch [151/500], test_loss: 1.6184978485107422, test_accuracy: 0.40625\n",
            "Batch [152/500], test_loss: 1.6333210468292236, test_accuracy: 0.421875\n",
            "Batch [153/500], test_loss: 1.6115001440048218, test_accuracy: 0.453125\n",
            "Batch [154/500], test_loss: 1.660571575164795, test_accuracy: 0.4375\n",
            "Batch [155/500], test_loss: 1.5939934253692627, test_accuracy: 0.46875\n",
            "Batch [156/500], test_loss: 1.5523048639297485, test_accuracy: 0.421875\n",
            "Batch [157/500], test_loss: 1.710899829864502, test_accuracy: 0.40625\n",
            "Batch [158/500], test_loss: 1.5475091934204102, test_accuracy: 0.421875\n",
            "Batch [159/500], test_loss: 1.5528770685195923, test_accuracy: 0.4375\n",
            "Batch [160/500], test_loss: 1.6324959993362427, test_accuracy: 0.421875\n",
            "Batch [161/500], test_loss: 1.6501374244689941, test_accuracy: 0.40625\n",
            "Batch [162/500], test_loss: 1.2845301628112793, test_accuracy: 0.515625\n",
            "Batch [163/500], test_loss: 1.5703849792480469, test_accuracy: 0.53125\n",
            "Batch [164/500], test_loss: 1.5392074584960938, test_accuracy: 0.4375\n",
            "Batch [165/500], test_loss: 1.5072174072265625, test_accuracy: 0.453125\n",
            "Batch [166/500], test_loss: 1.5276211500167847, test_accuracy: 0.5\n",
            "Batch [167/500], test_loss: 1.5571630001068115, test_accuracy: 0.484375\n",
            "Batch [168/500], test_loss: 1.587636947631836, test_accuracy: 0.40625\n",
            "Batch [169/500], test_loss: 1.383709192276001, test_accuracy: 0.5\n",
            "Batch [170/500], test_loss: 1.6496806144714355, test_accuracy: 0.265625\n",
            "Batch [171/500], test_loss: 1.538438081741333, test_accuracy: 0.453125\n",
            "Batch [172/500], test_loss: 1.4065663814544678, test_accuracy: 0.546875\n",
            "Batch [173/500], test_loss: 1.5365556478500366, test_accuracy: 0.5625\n",
            "Batch [174/500], test_loss: 1.586204171180725, test_accuracy: 0.34375\n",
            "Batch [175/500], test_loss: 1.5499743223190308, test_accuracy: 0.53125\n",
            "Batch [176/500], test_loss: 1.5002905130386353, test_accuracy: 0.5\n",
            "Batch [177/500], test_loss: 1.74786376953125, test_accuracy: 0.359375\n",
            "Batch [178/500], test_loss: 1.700042724609375, test_accuracy: 0.421875\n",
            "Batch [179/500], test_loss: 1.4874649047851562, test_accuracy: 0.5625\n",
            "Batch [180/500], test_loss: 1.5147709846496582, test_accuracy: 0.4375\n",
            "Batch [181/500], test_loss: 1.3454440832138062, test_accuracy: 0.515625\n",
            "Batch [182/500], test_loss: 1.5989755392074585, test_accuracy: 0.4375\n",
            "Batch [183/500], test_loss: 1.3654347658157349, test_accuracy: 0.5\n",
            "Batch [184/500], test_loss: 1.5343090295791626, test_accuracy: 0.46875\n",
            "Batch [185/500], test_loss: 1.4599666595458984, test_accuracy: 0.515625\n",
            "Batch [186/500], test_loss: 1.367478847503662, test_accuracy: 0.5\n",
            "Batch [187/500], test_loss: 1.4241440296173096, test_accuracy: 0.578125\n",
            "Batch [188/500], test_loss: 1.8112847805023193, test_accuracy: 0.375\n",
            "Batch [189/500], test_loss: 1.8240635395050049, test_accuracy: 0.328125\n",
            "Batch [190/500], test_loss: 1.6344318389892578, test_accuracy: 0.4375\n",
            "Batch [191/500], test_loss: 1.40815007686615, test_accuracy: 0.484375\n",
            "Batch [192/500], test_loss: 1.5778076648712158, test_accuracy: 0.40625\n",
            "Batch [193/500], test_loss: 1.3997632265090942, test_accuracy: 0.515625\n",
            "Batch [194/500], test_loss: 1.3351110219955444, test_accuracy: 0.546875\n",
            "Batch [195/500], test_loss: 1.7629523277282715, test_accuracy: 0.375\n",
            "Batch [196/500], test_loss: 1.6605582237243652, test_accuracy: 0.4375\n",
            "Batch [197/500], test_loss: 1.4278109073638916, test_accuracy: 0.484375\n",
            "Batch [198/500], test_loss: 1.8352309465408325, test_accuracy: 0.328125\n",
            "Batch [199/500], test_loss: 1.9402881860733032, test_accuracy: 0.328125\n",
            "Batch [200/500], test_loss: 1.5202467441558838, test_accuracy: 0.40625\n",
            "Batch [201/500], test_loss: 1.593855381011963, test_accuracy: 0.421875\n",
            "Batch [202/500], test_loss: 1.6481462717056274, test_accuracy: 0.390625\n",
            "Batch [203/500], test_loss: 1.6214382648468018, test_accuracy: 0.4375\n",
            "Batch [204/500], test_loss: 1.5556761026382446, test_accuracy: 0.390625\n",
            "Batch [205/500], test_loss: 1.7498642206192017, test_accuracy: 0.421875\n",
            "Batch [206/500], test_loss: 1.7172819375991821, test_accuracy: 0.28125\n",
            "Batch [207/500], test_loss: 1.5694011449813843, test_accuracy: 0.5\n",
            "Batch [208/500], test_loss: 1.7405368089675903, test_accuracy: 0.375\n",
            "Batch [209/500], test_loss: 1.6973540782928467, test_accuracy: 0.34375\n",
            "Batch [210/500], test_loss: 1.60310697555542, test_accuracy: 0.515625\n",
            "Batch [211/500], test_loss: 1.4755274057388306, test_accuracy: 0.453125\n",
            "Batch [212/500], test_loss: 1.4325677156448364, test_accuracy: 0.46875\n",
            "Batch [213/500], test_loss: 1.4646573066711426, test_accuracy: 0.453125\n",
            "Batch [214/500], test_loss: 1.647157073020935, test_accuracy: 0.390625\n",
            "Batch [215/500], test_loss: 1.6797828674316406, test_accuracy: 0.359375\n",
            "Batch [216/500], test_loss: 1.6193948984146118, test_accuracy: 0.4375\n",
            "Batch [217/500], test_loss: 1.4456813335418701, test_accuracy: 0.453125\n",
            "Batch [218/500], test_loss: 1.7051091194152832, test_accuracy: 0.328125\n",
            "Batch [219/500], test_loss: 1.449444055557251, test_accuracy: 0.59375\n",
            "Batch [220/500], test_loss: 1.7660229206085205, test_accuracy: 0.34375\n",
            "Batch [221/500], test_loss: 1.5325798988342285, test_accuracy: 0.46875\n",
            "Batch [222/500], test_loss: 1.421566367149353, test_accuracy: 0.421875\n",
            "Batch [223/500], test_loss: 1.6428208351135254, test_accuracy: 0.390625\n",
            "Batch [224/500], test_loss: 1.6952661275863647, test_accuracy: 0.421875\n",
            "Batch [225/500], test_loss: 1.5445735454559326, test_accuracy: 0.375\n",
            "Batch [226/500], test_loss: 1.5058937072753906, test_accuracy: 0.46875\n",
            "Batch [227/500], test_loss: 1.5418506860733032, test_accuracy: 0.4375\n",
            "Batch [228/500], test_loss: 1.7021231651306152, test_accuracy: 0.40625\n",
            "Batch [229/500], test_loss: 1.4524624347686768, test_accuracy: 0.546875\n",
            "Batch [230/500], test_loss: 1.6793363094329834, test_accuracy: 0.390625\n",
            "Batch [231/500], test_loss: 1.573506236076355, test_accuracy: 0.515625\n",
            "Batch [232/500], test_loss: 1.5680108070373535, test_accuracy: 0.46875\n",
            "Batch [233/500], test_loss: 1.4865113496780396, test_accuracy: 0.5\n",
            "Batch [234/500], test_loss: 1.7000813484191895, test_accuracy: 0.375\n",
            "Batch [235/500], test_loss: 1.5204516649246216, test_accuracy: 0.390625\n",
            "Batch [236/500], test_loss: 1.432837963104248, test_accuracy: 0.546875\n",
            "Batch [237/500], test_loss: 1.5244288444519043, test_accuracy: 0.53125\n",
            "Batch [238/500], test_loss: 1.3392598628997803, test_accuracy: 0.53125\n",
            "Batch [239/500], test_loss: 1.6286863088607788, test_accuracy: 0.375\n",
            "Batch [240/500], test_loss: 1.403789758682251, test_accuracy: 0.46875\n",
            "Batch [241/500], test_loss: 1.527201771736145, test_accuracy: 0.421875\n",
            "Batch [242/500], test_loss: 1.5135716199874878, test_accuracy: 0.4375\n",
            "Batch [243/500], test_loss: 1.392052173614502, test_accuracy: 0.484375\n",
            "Batch [244/500], test_loss: 1.5335086584091187, test_accuracy: 0.515625\n",
            "Batch [245/500], test_loss: 1.4267663955688477, test_accuracy: 0.484375\n",
            "Batch [246/500], test_loss: 1.5896716117858887, test_accuracy: 0.53125\n",
            "Batch [247/500], test_loss: 1.5285589694976807, test_accuracy: 0.46875\n",
            "Batch [248/500], test_loss: 1.7302000522613525, test_accuracy: 0.34375\n",
            "Batch [249/500], test_loss: 1.4074150323867798, test_accuracy: 0.53125\n",
            "Batch [250/500], test_loss: 1.4000381231307983, test_accuracy: 0.484375\n",
            "Batch [251/500], test_loss: 1.5954811573028564, test_accuracy: 0.375\n",
            "Batch [252/500], test_loss: 1.4939994812011719, test_accuracy: 0.4375\n",
            "Batch [253/500], test_loss: 1.5009028911590576, test_accuracy: 0.53125\n",
            "Batch [254/500], test_loss: 1.6215438842773438, test_accuracy: 0.34375\n",
            "Batch [255/500], test_loss: 1.5495935678482056, test_accuracy: 0.484375\n",
            "Batch [256/500], test_loss: 1.5046170949935913, test_accuracy: 0.484375\n",
            "Batch [257/500], test_loss: 1.7262091636657715, test_accuracy: 0.34375\n",
            "Batch [258/500], test_loss: 1.556461215019226, test_accuracy: 0.484375\n",
            "Batch [259/500], test_loss: 1.3760970830917358, test_accuracy: 0.484375\n",
            "Batch [260/500], test_loss: 1.587548851966858, test_accuracy: 0.375\n",
            "Batch [261/500], test_loss: 1.5151569843292236, test_accuracy: 0.453125\n",
            "Batch [262/500], test_loss: 1.6055793762207031, test_accuracy: 0.453125\n",
            "Batch [263/500], test_loss: 1.4175617694854736, test_accuracy: 0.390625\n",
            "Batch [264/500], test_loss: 1.5440500974655151, test_accuracy: 0.390625\n",
            "Batch [265/500], test_loss: 1.7578948736190796, test_accuracy: 0.390625\n",
            "Batch [266/500], test_loss: 1.7907264232635498, test_accuracy: 0.296875\n",
            "Batch [267/500], test_loss: 1.740375280380249, test_accuracy: 0.34375\n",
            "Batch [268/500], test_loss: 1.3288698196411133, test_accuracy: 0.484375\n",
            "Batch [269/500], test_loss: 1.8997951745986938, test_accuracy: 0.375\n",
            "Batch [270/500], test_loss: 1.5487744808197021, test_accuracy: 0.4375\n",
            "Batch [271/500], test_loss: 1.4766241312026978, test_accuracy: 0.484375\n",
            "Batch [272/500], test_loss: 1.8036764860153198, test_accuracy: 0.40625\n",
            "Batch [273/500], test_loss: 1.7029564380645752, test_accuracy: 0.390625\n",
            "Batch [274/500], test_loss: 1.456013798713684, test_accuracy: 0.46875\n",
            "Batch [275/500], test_loss: 1.6358048915863037, test_accuracy: 0.421875\n",
            "Batch [276/500], test_loss: 1.5309730768203735, test_accuracy: 0.421875\n",
            "Batch [277/500], test_loss: 1.5824394226074219, test_accuracy: 0.40625\n",
            "Batch [278/500], test_loss: 1.555412769317627, test_accuracy: 0.4375\n",
            "Batch [279/500], test_loss: 1.682026982307434, test_accuracy: 0.359375\n",
            "Batch [280/500], test_loss: 1.5742971897125244, test_accuracy: 0.453125\n",
            "Batch [281/500], test_loss: 1.4822938442230225, test_accuracy: 0.484375\n",
            "Batch [282/500], test_loss: 1.6080362796783447, test_accuracy: 0.421875\n",
            "Batch [283/500], test_loss: 1.6547129154205322, test_accuracy: 0.40625\n",
            "Batch [284/500], test_loss: 1.6095547676086426, test_accuracy: 0.421875\n",
            "Batch [285/500], test_loss: 1.5314205884933472, test_accuracy: 0.53125\n",
            "Batch [286/500], test_loss: 1.641957402229309, test_accuracy: 0.375\n",
            "Batch [287/500], test_loss: 1.4908101558685303, test_accuracy: 0.4375\n",
            "Batch [288/500], test_loss: 1.79281485080719, test_accuracy: 0.328125\n",
            "Batch [289/500], test_loss: 1.5163277387619019, test_accuracy: 0.40625\n",
            "Batch [290/500], test_loss: 1.4865915775299072, test_accuracy: 0.4375\n",
            "Batch [291/500], test_loss: 1.549469232559204, test_accuracy: 0.4375\n",
            "Batch [292/500], test_loss: 1.4999239444732666, test_accuracy: 0.515625\n",
            "Batch [293/500], test_loss: 1.4755719900131226, test_accuracy: 0.453125\n",
            "Batch [294/500], test_loss: 1.6080901622772217, test_accuracy: 0.375\n",
            "Batch [295/500], test_loss: 1.661050796508789, test_accuracy: 0.390625\n",
            "Batch [296/500], test_loss: 1.2835749387741089, test_accuracy: 0.53125\n",
            "Batch [297/500], test_loss: 1.373767375946045, test_accuracy: 0.53125\n",
            "Batch [298/500], test_loss: 1.5202622413635254, test_accuracy: 0.421875\n",
            "Batch [299/500], test_loss: 1.626800537109375, test_accuracy: 0.40625\n",
            "Batch [300/500], test_loss: 1.8859195709228516, test_accuracy: 0.328125\n",
            "Batch [301/500], test_loss: 1.6255630254745483, test_accuracy: 0.421875\n",
            "Batch [302/500], test_loss: 1.4846528768539429, test_accuracy: 0.5\n",
            "Batch [303/500], test_loss: 1.7392903566360474, test_accuracy: 0.390625\n",
            "Batch [304/500], test_loss: 1.4797097444534302, test_accuracy: 0.515625\n",
            "Batch [305/500], test_loss: 1.5831444263458252, test_accuracy: 0.390625\n",
            "Batch [306/500], test_loss: 1.5598713159561157, test_accuracy: 0.421875\n",
            "Batch [307/500], test_loss: 1.4777500629425049, test_accuracy: 0.578125\n",
            "Batch [308/500], test_loss: 1.7143160104751587, test_accuracy: 0.375\n",
            "Batch [309/500], test_loss: 1.6338896751403809, test_accuracy: 0.421875\n",
            "Batch [310/500], test_loss: 1.5565211772918701, test_accuracy: 0.453125\n",
            "Batch [311/500], test_loss: 1.5753670930862427, test_accuracy: 0.40625\n",
            "Batch [312/500], test_loss: 1.563106894493103, test_accuracy: 0.40625\n",
            "Batch [313/500], test_loss: 1.662475347518921, test_accuracy: 0.359375\n",
            "Batch [314/500], test_loss: 1.5553542375564575, test_accuracy: 0.359375\n",
            "Batch [315/500], test_loss: 1.4166972637176514, test_accuracy: 0.5\n",
            "Batch [316/500], test_loss: 1.6902626752853394, test_accuracy: 0.34375\n",
            "Batch [317/500], test_loss: 1.7065032720565796, test_accuracy: 0.328125\n",
            "Batch [318/500], test_loss: 1.6296541690826416, test_accuracy: 0.4375\n",
            "Batch [319/500], test_loss: 1.4702283143997192, test_accuracy: 0.5\n",
            "Batch [320/500], test_loss: 1.6685481071472168, test_accuracy: 0.359375\n",
            "Batch [321/500], test_loss: 1.6870886087417603, test_accuracy: 0.375\n",
            "Batch [322/500], test_loss: 1.4768223762512207, test_accuracy: 0.4375\n",
            "Batch [323/500], test_loss: 1.5073643922805786, test_accuracy: 0.46875\n",
            "Batch [324/500], test_loss: 1.8663108348846436, test_accuracy: 0.390625\n",
            "Batch [325/500], test_loss: 1.4866609573364258, test_accuracy: 0.46875\n",
            "Batch [326/500], test_loss: 1.5717694759368896, test_accuracy: 0.46875\n",
            "Batch [327/500], test_loss: 1.7510390281677246, test_accuracy: 0.390625\n",
            "Batch [328/500], test_loss: 1.6145730018615723, test_accuracy: 0.5\n",
            "Batch [329/500], test_loss: 1.5537958145141602, test_accuracy: 0.53125\n",
            "Batch [330/500], test_loss: 1.835862398147583, test_accuracy: 0.375\n",
            "Batch [331/500], test_loss: 1.5502843856811523, test_accuracy: 0.46875\n",
            "Batch [332/500], test_loss: 1.5577977895736694, test_accuracy: 0.484375\n",
            "Batch [333/500], test_loss: 1.8220577239990234, test_accuracy: 0.34375\n",
            "Batch [334/500], test_loss: 1.4719456434249878, test_accuracy: 0.40625\n",
            "Batch [335/500], test_loss: 1.5438485145568848, test_accuracy: 0.421875\n",
            "Batch [336/500], test_loss: 1.4699667692184448, test_accuracy: 0.4375\n",
            "Batch [337/500], test_loss: 1.6521772146224976, test_accuracy: 0.328125\n",
            "Batch [338/500], test_loss: 1.6633665561676025, test_accuracy: 0.484375\n",
            "Batch [339/500], test_loss: 1.668711543083191, test_accuracy: 0.34375\n",
            "Batch [340/500], test_loss: 1.4707781076431274, test_accuracy: 0.453125\n",
            "Batch [341/500], test_loss: 1.6682765483856201, test_accuracy: 0.4375\n",
            "Batch [342/500], test_loss: 1.5938975811004639, test_accuracy: 0.421875\n",
            "Batch [343/500], test_loss: 1.721193552017212, test_accuracy: 0.359375\n",
            "Batch [344/500], test_loss: 1.7071465253829956, test_accuracy: 0.40625\n",
            "Batch [345/500], test_loss: 1.833804726600647, test_accuracy: 0.390625\n",
            "Batch [346/500], test_loss: 1.9142849445343018, test_accuracy: 0.296875\n",
            "Batch [347/500], test_loss: 1.862709641456604, test_accuracy: 0.328125\n",
            "Batch [348/500], test_loss: 1.4885324239730835, test_accuracy: 0.53125\n",
            "Batch [349/500], test_loss: 1.627856969833374, test_accuracy: 0.390625\n",
            "Batch [350/500], test_loss: 1.7481149435043335, test_accuracy: 0.34375\n",
            "Batch [351/500], test_loss: 1.7125120162963867, test_accuracy: 0.4375\n",
            "Batch [352/500], test_loss: 1.635441541671753, test_accuracy: 0.40625\n",
            "Batch [353/500], test_loss: 1.6241449117660522, test_accuracy: 0.4375\n",
            "Batch [354/500], test_loss: 1.6107666492462158, test_accuracy: 0.421875\n",
            "Batch [355/500], test_loss: 1.6231038570404053, test_accuracy: 0.4375\n",
            "Batch [356/500], test_loss: 1.62962806224823, test_accuracy: 0.390625\n",
            "Batch [357/500], test_loss: 1.3884284496307373, test_accuracy: 0.515625\n",
            "Batch [358/500], test_loss: 1.6532257795333862, test_accuracy: 0.390625\n",
            "Batch [359/500], test_loss: 1.6384458541870117, test_accuracy: 0.453125\n",
            "Batch [360/500], test_loss: 1.5014655590057373, test_accuracy: 0.40625\n",
            "Batch [361/500], test_loss: 1.6094748973846436, test_accuracy: 0.4375\n",
            "Batch [362/500], test_loss: 1.5049904584884644, test_accuracy: 0.546875\n",
            "Batch [363/500], test_loss: 1.5367835760116577, test_accuracy: 0.453125\n",
            "Batch [364/500], test_loss: 1.5061068534851074, test_accuracy: 0.453125\n",
            "Batch [365/500], test_loss: 1.3953547477722168, test_accuracy: 0.515625\n",
            "Batch [366/500], test_loss: 1.6514557600021362, test_accuracy: 0.390625\n",
            "Batch [367/500], test_loss: 1.402880311012268, test_accuracy: 0.5625\n",
            "Batch [368/500], test_loss: 1.5223886966705322, test_accuracy: 0.453125\n",
            "Batch [369/500], test_loss: 1.7556169033050537, test_accuracy: 0.375\n",
            "Batch [370/500], test_loss: 1.7131726741790771, test_accuracy: 0.375\n",
            "Batch [371/500], test_loss: 1.5802804231643677, test_accuracy: 0.46875\n",
            "Batch [372/500], test_loss: 1.5422260761260986, test_accuracy: 0.453125\n",
            "Batch [373/500], test_loss: 1.628758430480957, test_accuracy: 0.453125\n",
            "Batch [374/500], test_loss: 1.5369873046875, test_accuracy: 0.484375\n",
            "Batch [375/500], test_loss: 1.434952974319458, test_accuracy: 0.453125\n",
            "Batch [376/500], test_loss: 1.7492403984069824, test_accuracy: 0.5\n",
            "Batch [377/500], test_loss: 1.7231471538543701, test_accuracy: 0.421875\n",
            "Batch [378/500], test_loss: 1.5583088397979736, test_accuracy: 0.34375\n",
            "Batch [379/500], test_loss: 1.8428374528884888, test_accuracy: 0.328125\n",
            "Batch [380/500], test_loss: 1.5059585571289062, test_accuracy: 0.5\n",
            "Batch [381/500], test_loss: 1.4375193119049072, test_accuracy: 0.515625\n",
            "Batch [382/500], test_loss: 1.6366815567016602, test_accuracy: 0.390625\n",
            "Batch [383/500], test_loss: 1.5834121704101562, test_accuracy: 0.34375\n",
            "Batch [384/500], test_loss: 1.8818635940551758, test_accuracy: 0.375\n",
            "Batch [385/500], test_loss: 1.511214017868042, test_accuracy: 0.5\n",
            "Batch [386/500], test_loss: 1.6413164138793945, test_accuracy: 0.484375\n",
            "Batch [387/500], test_loss: 1.5367411375045776, test_accuracy: 0.4375\n",
            "Batch [388/500], test_loss: 1.6184980869293213, test_accuracy: 0.34375\n",
            "Batch [389/500], test_loss: 1.462851643562317, test_accuracy: 0.453125\n",
            "Batch [390/500], test_loss: 1.581432580947876, test_accuracy: 0.40625\n",
            "Batch [391/500], test_loss: 1.5737454891204834, test_accuracy: 0.4375\n",
            "Batch [392/500], test_loss: 1.4985312223434448, test_accuracy: 0.4375\n",
            "Batch [393/500], test_loss: 1.7124053239822388, test_accuracy: 0.390625\n",
            "Batch [394/500], test_loss: 1.4858245849609375, test_accuracy: 0.515625\n",
            "Batch [395/500], test_loss: 1.5367757081985474, test_accuracy: 0.359375\n",
            "Batch [396/500], test_loss: 1.4120147228240967, test_accuracy: 0.5\n",
            "Batch [397/500], test_loss: 1.4729381799697876, test_accuracy: 0.5\n",
            "Batch [398/500], test_loss: 1.473189353942871, test_accuracy: 0.515625\n",
            "Batch [399/500], test_loss: 1.5931035280227661, test_accuracy: 0.421875\n",
            "Batch [400/500], test_loss: 1.4307441711425781, test_accuracy: 0.546875\n",
            "Batch [401/500], test_loss: 1.7499476671218872, test_accuracy: 0.40625\n",
            "Batch [402/500], test_loss: 1.5536363124847412, test_accuracy: 0.40625\n",
            "Batch [403/500], test_loss: 1.5719692707061768, test_accuracy: 0.546875\n",
            "Batch [404/500], test_loss: 1.5865153074264526, test_accuracy: 0.421875\n",
            "Batch [405/500], test_loss: 1.6091759204864502, test_accuracy: 0.4375\n",
            "Batch [406/500], test_loss: 1.750552773475647, test_accuracy: 0.359375\n",
            "Batch [407/500], test_loss: 1.4996709823608398, test_accuracy: 0.453125\n",
            "Batch [408/500], test_loss: 1.4767943620681763, test_accuracy: 0.484375\n",
            "Batch [409/500], test_loss: 1.445143699645996, test_accuracy: 0.453125\n",
            "Batch [410/500], test_loss: 1.4608795642852783, test_accuracy: 0.5\n",
            "Batch [411/500], test_loss: 1.555844783782959, test_accuracy: 0.453125\n",
            "Batch [412/500], test_loss: 1.598929762840271, test_accuracy: 0.390625\n",
            "Batch [413/500], test_loss: 1.6112821102142334, test_accuracy: 0.421875\n",
            "Batch [414/500], test_loss: 1.553608775138855, test_accuracy: 0.4375\n",
            "Batch [415/500], test_loss: 1.3635950088500977, test_accuracy: 0.53125\n",
            "Batch [416/500], test_loss: 1.574270486831665, test_accuracy: 0.359375\n",
            "Batch [417/500], test_loss: 1.7967051267623901, test_accuracy: 0.3125\n",
            "Batch [418/500], test_loss: 1.582041621208191, test_accuracy: 0.484375\n",
            "Batch [419/500], test_loss: 1.7015796899795532, test_accuracy: 0.359375\n",
            "Batch [420/500], test_loss: 1.599488615989685, test_accuracy: 0.4375\n",
            "Batch [421/500], test_loss: 1.8528941869735718, test_accuracy: 0.359375\n",
            "Batch [422/500], test_loss: 1.610239028930664, test_accuracy: 0.40625\n",
            "Batch [423/500], test_loss: 1.7460157871246338, test_accuracy: 0.359375\n",
            "Batch [424/500], test_loss: 1.5203588008880615, test_accuracy: 0.453125\n",
            "Batch [425/500], test_loss: 1.5684880018234253, test_accuracy: 0.421875\n",
            "Batch [426/500], test_loss: 1.5691992044448853, test_accuracy: 0.5\n",
            "Batch [427/500], test_loss: 1.5567455291748047, test_accuracy: 0.359375\n",
            "Batch [428/500], test_loss: 1.5833470821380615, test_accuracy: 0.390625\n",
            "Batch [429/500], test_loss: 1.5089391469955444, test_accuracy: 0.484375\n",
            "Batch [430/500], test_loss: 2.063115358352661, test_accuracy: 0.3125\n",
            "Batch [431/500], test_loss: 1.5377779006958008, test_accuracy: 0.453125\n",
            "Batch [432/500], test_loss: 1.7685120105743408, test_accuracy: 0.375\n",
            "Batch [433/500], test_loss: 1.5937930345535278, test_accuracy: 0.40625\n",
            "Batch [434/500], test_loss: 1.5843944549560547, test_accuracy: 0.453125\n",
            "Batch [435/500], test_loss: 1.4472875595092773, test_accuracy: 0.515625\n",
            "Batch [436/500], test_loss: 1.381409764289856, test_accuracy: 0.59375\n",
            "Batch [437/500], test_loss: 1.7272289991378784, test_accuracy: 0.375\n",
            "Batch [438/500], test_loss: 1.6200073957443237, test_accuracy: 0.375\n",
            "Batch [439/500], test_loss: 1.4709113836288452, test_accuracy: 0.421875\n",
            "Batch [440/500], test_loss: 1.4449658393859863, test_accuracy: 0.4375\n",
            "Batch [441/500], test_loss: 1.551852822303772, test_accuracy: 0.390625\n",
            "Batch [442/500], test_loss: 1.6233798265457153, test_accuracy: 0.4375\n",
            "Batch [443/500], test_loss: 1.5222394466400146, test_accuracy: 0.5\n",
            "Batch [444/500], test_loss: 1.5706480741500854, test_accuracy: 0.40625\n",
            "Batch [445/500], test_loss: 1.5431867837905884, test_accuracy: 0.40625\n",
            "Batch [446/500], test_loss: 1.8240278959274292, test_accuracy: 0.390625\n",
            "Batch [447/500], test_loss: 1.5041943788528442, test_accuracy: 0.5625\n",
            "Batch [448/500], test_loss: 1.6543267965316772, test_accuracy: 0.4375\n",
            "Batch [449/500], test_loss: 1.5266175270080566, test_accuracy: 0.453125\n",
            "Batch [450/500], test_loss: 1.6904900074005127, test_accuracy: 0.40625\n",
            "Batch [451/500], test_loss: 1.430670142173767, test_accuracy: 0.484375\n",
            "Batch [452/500], test_loss: 1.6497079133987427, test_accuracy: 0.453125\n",
            "Batch [453/500], test_loss: 1.4387123584747314, test_accuracy: 0.515625\n",
            "Batch [454/500], test_loss: 1.6830686330795288, test_accuracy: 0.328125\n",
            "Batch [455/500], test_loss: 1.5020241737365723, test_accuracy: 0.4375\n",
            "Batch [456/500], test_loss: 1.6690919399261475, test_accuracy: 0.390625\n",
            "Batch [457/500], test_loss: 1.422855019569397, test_accuracy: 0.4375\n",
            "Batch [458/500], test_loss: 1.4708820581436157, test_accuracy: 0.453125\n",
            "Batch [459/500], test_loss: 1.4676557779312134, test_accuracy: 0.484375\n",
            "Batch [460/500], test_loss: 1.7098181247711182, test_accuracy: 0.390625\n",
            "Batch [461/500], test_loss: 1.444939136505127, test_accuracy: 0.515625\n",
            "Batch [462/500], test_loss: 1.5625934600830078, test_accuracy: 0.40625\n",
            "Batch [463/500], test_loss: 1.5478568077087402, test_accuracy: 0.40625\n",
            "Batch [464/500], test_loss: 1.716498613357544, test_accuracy: 0.375\n",
            "Batch [465/500], test_loss: 1.5158370733261108, test_accuracy: 0.484375\n",
            "Batch [466/500], test_loss: 1.6046652793884277, test_accuracy: 0.46875\n",
            "Batch [467/500], test_loss: 1.7464786767959595, test_accuracy: 0.34375\n",
            "Batch [468/500], test_loss: 1.7912209033966064, test_accuracy: 0.359375\n",
            "Batch [469/500], test_loss: 1.5192322731018066, test_accuracy: 0.515625\n",
            "Batch [470/500], test_loss: 1.8050075769424438, test_accuracy: 0.4375\n",
            "Batch [471/500], test_loss: 1.5150117874145508, test_accuracy: 0.453125\n",
            "Batch [472/500], test_loss: 1.4102249145507812, test_accuracy: 0.546875\n",
            "Batch [473/500], test_loss: 1.6577788591384888, test_accuracy: 0.375\n",
            "Batch [474/500], test_loss: 1.7934863567352295, test_accuracy: 0.375\n",
            "Batch [475/500], test_loss: 1.595094084739685, test_accuracy: 0.421875\n",
            "Batch [476/500], test_loss: 1.5523462295532227, test_accuracy: 0.484375\n",
            "Batch [477/500], test_loss: 1.3959784507751465, test_accuracy: 0.515625\n",
            "Batch [478/500], test_loss: 1.413415551185608, test_accuracy: 0.46875\n",
            "Batch [479/500], test_loss: 1.578557014465332, test_accuracy: 0.421875\n",
            "Batch [480/500], test_loss: 1.7464733123779297, test_accuracy: 0.4375\n",
            "Batch [481/500], test_loss: 1.6878397464752197, test_accuracy: 0.375\n",
            "Batch [482/500], test_loss: 1.637644648551941, test_accuracy: 0.453125\n",
            "Batch [483/500], test_loss: 1.3345867395401, test_accuracy: 0.5625\n",
            "Batch [484/500], test_loss: 1.6989049911499023, test_accuracy: 0.453125\n",
            "Batch [485/500], test_loss: 1.5422420501708984, test_accuracy: 0.453125\n",
            "Batch [486/500], test_loss: 1.652307152748108, test_accuracy: 0.328125\n",
            "Batch [487/500], test_loss: 1.6165655851364136, test_accuracy: 0.421875\n",
            "Batch [488/500], test_loss: 1.598585844039917, test_accuracy: 0.4375\n",
            "Batch [489/500], test_loss: 1.7078938484191895, test_accuracy: 0.34375\n",
            "Batch [490/500], test_loss: 1.6536123752593994, test_accuracy: 0.484375\n",
            "Batch [491/500], test_loss: 1.4468556642532349, test_accuracy: 0.53125\n",
            "Batch [492/500], test_loss: 1.4910112619400024, test_accuracy: 0.546875\n",
            "Batch [493/500], test_loss: 1.5087183713912964, test_accuracy: 0.46875\n",
            "Batch [494/500], test_loss: 1.599994421005249, test_accuracy: 0.359375\n",
            "Batch [495/500], test_loss: 1.508487582206726, test_accuracy: 0.5\n",
            "Batch [496/500], test_loss: 1.520906686782837, test_accuracy: 0.5\n",
            "Batch [497/500], test_loss: 1.527937412261963, test_accuracy: 0.46875\n",
            "Batch [498/500], test_loss: 1.5251927375793457, test_accuracy: 0.484375\n",
            "Batch [499/500], test_loss: 1.7707291841506958, test_accuracy: 0.3125\n",
            "Batch [500/500], test_loss: 1.6555781364440918, test_accuracy: 0.40625\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.5775572588443756, 0.43834375)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "execution_count": 37
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3810482fe9e960bf",
        "outputId": "0b3bffc5-f445-483d-f20d-14023c04ee9a",
        "ExecuteTime": {
          "end_time": "2024-06-13T02:38:47.698327Z",
          "start_time": "2024-06-13T02:38:47.680801Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def eye_test(model,puzzle):\n",
        "    tensor=puzzle_to_tensor(puzzle).cuda()\n",
        "    out=model.forward(tensor)\n",
        "    return sorted(zip(expected_tags_list,out.squeeze().tolist()),key=lambda x:-x[1]),puzzle.tags\n",
        "\n",
        "eye_test(model,filter_data(load(100))[0])"
      ],
      "id": "3810482fe9e960bf",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('fork', -1.4304933547973633),\n",
              "  ('deflection', -1.6195344924926758),\n",
              "  ('skewer', -1.8068654537200928),\n",
              "  ('pin', -2.0664966106414795),\n",
              "  ('discoveredAttack', -2.3324050903320312),\n",
              "  ('sacrifice', -2.383424758911133),\n",
              "  ('attraction', -3.242687940597534),\n",
              "  ('clearance', -3.7647244930267334),\n",
              "  ('zugzwang', -4.711508750915527),\n",
              "  ('xRayAttack', -4.775970458984375),\n",
              "  ('doubleCheck', -5.785516738891602)],\n",
              " ['crushing', 'endgame', 'exposedKing', 'long', 'skewer'])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "execution_count": 38
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random',  # random, grid or bayes\n",
        "    'name': 'sweep-chess-tactics',\n",
        "    'metric': {'goal': 'minimize', 'name': 'train_loss'},\n",
        "    'parameters':\n",
        "    {\n",
        "        # 'batch_size': {'values': [64, 128, 256]},\n",
        "        'epochs': {'values': [5, 10, 15]},\n",
        "        # 'learning_rate': {'values': [0.1, 0.01, 0.001]},\n",
        "        'learning_rate': {'values': [0.001]},\n",
        "        # 'learning_rate': {'max': 0.1, 'min': 0.0001},\n",
        "        'optimizer': {\n",
        "            'values': ['sgd', 'adam']\n",
        "        },\n",
        "        'criterion': {\n",
        "            'values': ['NLLLoss']\n",
        "        },\n",
        "     },\n",
        "\n",
        "}\n",
        "\n",
        "def create_optimizer(model, optimizer):\n",
        "    if optimizer == \"sgd\":\n",
        "        optimizer = torch.optim.SGD\n",
        "    elif optimizer == \"adam\":\n",
        "        optimizer = torch.optim.Adam\n",
        "    return optimizer\n",
        "\n",
        "def create_criterion(criterion = \"NLLLoss\"):\n",
        "    if criterion == \"NLLLoss\":\n",
        "        return nn.NLLLoss()\n",
        "\n",
        "def main(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        opt_fn = create_optimizer(model, wandb.config.optimizer)\n",
        "        crt_fn = create_criterion(wandb.config.criterion)\n",
        "        train(model, crt_fn, opt_fn(model.classifier.parameters(), lr=wandb.config.learning_rate), wandb.config.epochs)\n",
        "        # train(model, criterion, opt_fn(model.classifier.parameters(), lr=wandb.config.learning_rate), wandb.config.epochs)\n",
        "\n",
        "\n",
        "if use_wandb:\n",
        "    sweep_id = wandb.sweep(sweep_config, project=\"chess-tactics-swp\")\n",
        "    wandb.agent(sweep_id, main, count=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "fpBNlykTP7kP",
        "outputId": "d1a0e42d-ff31-42d3-ae35-18f7b7f9a801"
      },
      "id": "fpBNlykTP7kP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: u8y52lv7\n",
            "Sweep URL: https://wandb.ai/wsniady-org/chess-tactics-swp/sweeps/u8y52lv7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q5lhy4q3 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: NLLLoss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240614_150410-q5lhy4q3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/wsniady-org/chess-tactics-swp/runs/q5lhy4q3' target=\"_blank\">true-sweep-1</a></strong> to <a href='https://wandb.ai/wsniady-org/chess-tactics-swp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/wsniady-org/chess-tactics-swp/sweeps/u8y52lv7' target=\"_blank\">https://wandb.ai/wsniady-org/chess-tactics-swp/sweeps/u8y52lv7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/wsniady-org/chess-tactics-swp' target=\"_blank\">https://wandb.ai/wsniady-org/chess-tactics-swp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/wsniady-org/chess-tactics-swp/sweeps/u8y52lv7' target=\"_blank\">https://wandb.ai/wsniady-org/chess-tactics-swp/sweeps/u8y52lv7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/wsniady-org/chess-tactics-swp/runs/q5lhy4q3' target=\"_blank\">https://wandb.ai/wsniady-org/chess-tactics-swp/runs/q5lhy4q3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 13631\n",
            "Epoch [1/10], train_loss: 1.187486183922321, train_accuracy: 0.5998081120240628, time: 59.478s\n",
            "Epoch [2/10], train_loss: 1.1814785171618563, train_accuracy: 0.6022267716968674, time: 60.54s\n",
            "Epoch [3/10], train_loss: 1.1771843292315947, train_accuracy: 0.6039278574572665, time: 59.747s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if use_wandb:\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "id": "KAUvPaHsP8cH"
      },
      "id": "KAUvPaHsP8cH",
      "execution_count": 40,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "name": "python3",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}